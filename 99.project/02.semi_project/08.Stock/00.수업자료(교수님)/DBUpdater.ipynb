{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql, calendar, time, json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from threading import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBUpdater: \n",
    "    def __init__(self):        \n",
    "        self.conn = pymysql.connect(host='localhost', user='root', \\\n",
    "            password='apple123!!', db='INVESTAR2', charset='utf8')\n",
    "            \n",
    "        with self.conn.cursor() as curs:\n",
    "            sql = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS company_info2 (\n",
    "                code VARCHAR(20),\n",
    "                company VARCHAR(40),\n",
    "                last_update DATE,\n",
    "                PRIMARY KEY (code))\n",
    "            \"\"\"\n",
    "            curs.execute(sql)\n",
    "            \n",
    "            sql = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS daily_price2 (\n",
    "                code VARCHAR(20),\n",
    "                date DATE,\n",
    "                open BIGINT(20),\n",
    "                high BIGINT(20),\n",
    "                low BIGINT(20),\n",
    "                close BIGINT(20),\n",
    "                diff BIGINT(20),\n",
    "                volume BIGINT(20),\n",
    "                PRIMARY KEY (code, date))\n",
    "            \"\"\"\n",
    "            curs.execute(sql)\n",
    "        \n",
    "        self.conn.commit()        \n",
    "        self.codes = dict()\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.conn.close() \n",
    "        \n",
    "    def read_krx_code(self):\n",
    "        url = 'http://kind.krx.co.kr/corpgeneral/corpList.do?method='\\\n",
    "            'download&searchType=13'\n",
    "            \n",
    "        krx = pd.read_html(url, header=0)[0]  \n",
    "        krx = krx[['종목코드', '회사명']]\n",
    "        krx = krx.rename(columns={'종목코드': 'code', '회사명': 'company'})\n",
    "        krx.code = krx.code.map('{:06d}'.format)\n",
    "        \n",
    "        return krx\n",
    "    \n",
    "    # 종목코드를 company_info 테이블에 업데이트 한 후 딕셔너리에(self.codes) 저장\n",
    "    def update_comp_info(self):\n",
    "        sql = \"SELECT * FROM company_info2\"\n",
    "        df = pd.read_sql(sql, self.conn)\n",
    "        for idx in range(len(df)):\n",
    "            self.codes[df['code'].values[idx]] = df['company'].values[idx]\n",
    "            \n",
    "        with self.conn.cursor() as curs:\n",
    "            sql = \"SELECT max(last_update) FROM company_info2\"\n",
    "            curs.execute(sql)\n",
    "            rs = curs.fetchone()\n",
    "            print(rs, rs[0])\n",
    "            \n",
    "            today = datetime.today().strftime('%Y-%m-%d')\n",
    "            if rs[0] == None or rs[0].strftime('%Y-%m-%d') < today:\n",
    "                krx = self.read_krx_code()\n",
    "                for idx in range(len(krx)):\n",
    "                    code = krx.code.values[idx]\n",
    "                    company = krx.company.values[idx]   \n",
    "                    sql = f\"REPLACE INTO company_info2 (code, company, last\"\\\n",
    "                        f\"_update) VALUES ('{code}', '{company}', '{today}')\"\n",
    "                    curs.execute(sql)\n",
    "\n",
    "                    tmnow = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "                    print(f\"[{tmnow}] #{idx+1:04d} REPLACE INTO company_info2 \"\\\n",
    "                            f\"VALUES ({code}, {company}, {today})\")    \n",
    "                \n",
    "                self.conn.commit()    \n",
    "    \n",
    "    # 네이버 데이터 수집            \n",
    "    def read_naver(self, code, company, pages_to_fetch):   \n",
    "        try:\n",
    "            url = f\"http://finance.naver.com/item/sise_day.nhn?code={code}\"\n",
    "            res = requests.get(url, headers={'User-agent': 'Mozilla/5.0'})\n",
    "            html = BeautifulSoup(res.text, \"lxml\")\n",
    "            \n",
    "            pgrr = html.find(\"td\", class_=\"pgRR\")\n",
    "            if pgrr is None:\n",
    "                return None\n",
    "            \n",
    "            s = str(pgrr.a[\"href\"]).split('=')\n",
    "            lastpage = s[-1]             \n",
    "            pages = min(int(lastpage), pages_to_fetch)\n",
    "            df = pd.DataFrame()      \n",
    "                  \n",
    "            for page in range(1, pages + 1):\n",
    "                pg_url = '{}&page={}'.format(url, page)\n",
    "                tmpDf = pd.read_html(requests.get(pg_url, headers={'User-agent': 'Mozilla/5.0'}).text)[0]\n",
    "                df = pd.concat([df, tmpDf], ignore_index=True)\n",
    "                #df = pd.concat([df, pd.DataFrame([pd.read_html(requests.get(pg_url,\n",
    "                #    headers={'User-agent': 'Mozilla/5.0'}).text)[0]])], ignore_index=True)\n",
    "                \n",
    "                tmnow = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "                print('[{}] {} ({}) : {:04d}/{:04d} pages are downloading...'.\n",
    "                    format(tmnow, company, code, page, pages), end=\"\\r\")\n",
    "                \n",
    "            df = df.rename(columns={'날짜':'date','종가':'close','전일비':'diff'\n",
    "                ,'시가':'open','고가':'high','저가':'low','거래량':'volume'})\n",
    "            df['date'] = df['date'].replace('.', '-')\n",
    "            df = df.dropna()\n",
    "            \n",
    "            df[['close', 'diff', 'open', 'high', 'low', 'volume']] = df[['close',\n",
    "                'diff', 'open', 'high', 'low', 'volume']].astype(int)\n",
    "            df = df[['date', 'open', 'high', 'low', 'close', 'diff', 'volume']]           \n",
    "        \n",
    "        except Exception as e:\n",
    "            print('Exception occured :', str(e))\n",
    "            return None\n",
    "        return df   \n",
    "    \n",
    "    def replace_into_db(self, df, num, code, company):\n",
    "        \"\"\"네이버에서 읽어온 주식 시세를 DB에 저장\"\"\"\n",
    "        with self.conn.cursor() as curs:\n",
    "            for r in df.itertuples():\n",
    "                sql = f\"REPLACE INTO daily_price2 VALUES ('{code}', \"\\\n",
    "                    f\"'{r.date}', {r.open}, {r.high}, {r.low}, {r.close}, \"\\\n",
    "                    f\"{r.diff}, {r.volume})\"\n",
    "                curs.execute(sql)\n",
    "            self.conn.commit()\n",
    "            \n",
    "            print('[{}] #{:04d} {} ({}) : {} rows > REPLACE INTO daily_'\\\n",
    "                'price2 [OK]'.format(datetime.now().strftime('%Y-%m-%d'\\\n",
    "                ' %H:%M'), num+1, company, code, len(df)))\n",
    "            \n",
    "    def update_daily_price(self, pages_to_fetch):\n",
    "        for idx, code in enumerate(self.codes):\n",
    "            df = self.read_naver(code, self.codes[code], pages_to_fetch)\n",
    "            if df is None:\n",
    "                continue\n",
    "            \n",
    "            self.replace_into_db(df, idx, code, self.codes[code])   \n",
    "            return \n",
    "        \n",
    "    def execute_daily(self):\n",
    "        self.update_comp_info()\n",
    "        \n",
    "        try:\n",
    "            with open('config.json', 'r') as in_file:\n",
    "                config = json.load(in_file)\n",
    "                pages_to_fetch = config['pages_to_fetch']\n",
    "        except FileNotFoundError:\n",
    "            with open('config.json', 'w') as out_file:\n",
    "                pages_to_fetch = 100\n",
    "                config = {'pages_to_fetch': pages_to_fetch}\n",
    "                json.dump(config, out_file)\n",
    "            \n",
    "        self.update_daily_price(pages_to_fetch)\n",
    "        \n",
    "        tmnow = datetime.now()\n",
    "        lastday = calendar.monthrange(tmnow.year, tmnow.month)[1]\n",
    "        if tmnow.month == 12 and tmnow.day == lastday:\n",
    "            tmnext = tmnow.replace(year=tmnow.year+1, month=1, day=1,\n",
    "                hour=17, minute=0, second=0)\n",
    "        elif tmnow.day == lastday:\n",
    "            tmnext = tmnow.replace(month=tmnow.month+1, day=1, hour=17,\n",
    "                minute=0, second=0)\n",
    "        else:\n",
    "            tmnext = tmnow.replace(day=tmnow.day+1, hour=17, minute=0,\n",
    "                second=0)   \n",
    "            \n",
    "        tmdiff = tmnext - tmnow\n",
    "        secs = tmdiff.seconds\n",
    "        \n",
    "        t = Timer(secs, self.execute_daily)\n",
    "        t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/tjfrq8vj411cyf6zll2ppq_w0000gn/T/ipykernel_4785/976295043.py:50: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql, self.conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2024, 1, 11),) 2024-01-11\n",
      "[2024-01-11 13:37] #0001 동화약품 (000020) : 1000 rows > REPLACE INTO daily_price2 [OK]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/tjfrq8vj411cyf6zll2ppq_w0000gn/T/ipykernel_4785/2856184959.py:50: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql, self.conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2024, 1, 11),) 2024-01-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/tjfrq8vj411cyf6zll2ppq_w0000gn/T/ipykernel_4785/1648501702.py:50: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql, self.conn)\n",
      "/var/folders/y6/tjfrq8vj411cyf6zll2ppq_w0000gn/T/ipykernel_4785/976295043.py:50: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql, self.conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2024, 1, 11),) 2024-01-11\n",
      "(datetime.date(2024, 1, 11),) 2024-01-110100 pages are downloading...\n",
      "[2024-01-11 17:41] #0001 동화약품 (000020) : 1000 rows > REPLACE INTO daily_price [OK]\n",
      "[2024-01-11 17:41] #0001 동화약품 (000020) : 1000 rows > REPLACE INTO daily_price [OK]\n",
      "[2024-01-11 17:41] #0001 동화약품 (000020) : 1000 rows > REPLACE INTO daily_price2 [OK]\n"
     ]
    }
   ],
   "source": [
    "dbu = DBUpdater()\n",
    "dbu.read_krx_code()\n",
    "dbu.execute_daily()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
