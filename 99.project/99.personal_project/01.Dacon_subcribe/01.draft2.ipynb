{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('./data_base/train.csv')\n",
    "test_df = pd.read_csv('./data_base/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()\n",
    "# user_id -> 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('user_id',axis=1,inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 문자 데이터 -> Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype_ object -> preferred_difficulty_level\tpreferred_difficulty_level -> label encoding\n",
    "train_df['preferred_difficulty_level'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['preferred_difficulty_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_sub = LabelEncoder()\n",
    "le_sub = le_sub.fit(train_df['subscription_type'])\n",
    "\n",
    "train_df['subscription_type'] = le_sub.transform(train_df['subscription_type'])\n",
    "train_df['subscription_type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_lev = LabelEncoder()\n",
    "le_lev = le_lev.fit(train_df['preferred_difficulty_level'])\n",
    "\n",
    "train_df['preferred_difficulty_level'] = le_lev.transform(train_df['preferred_difficulty_level'])\n",
    "train_df['preferred_difficulty_level'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이상치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(4,3, figsize = (20,30))\n",
    "\n",
    "for idx,col in enumerate(train_df.columns[1:13]):\n",
    "    \n",
    "    row_index = idx // 3\n",
    "    col_index = idx % 3\n",
    "\n",
    "    sns.boxplot(x = train_df['target'],y = train_df[col], color = 'darkseagreen', ax = ax[row_index,col_index])\n",
    "    ax[row_index,col_index].set_title('boxplot for %s' % col)\n",
    "plt.show()\n",
    "\n",
    "plt.tight_layout(pad=5)\n",
    "plt.subplots_adjust(wspace=0, hspace=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이상치 제거 없이 머신러닝 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# y_train = train_df['target']\n",
    "# X_train = train_df.drop('target',axis=1)\n",
    "\n",
    "# train_X,test_X,train_y,test_y = train_test_split(X_train,y_train,\n",
    "#                                                test_size=0.2,random_state=11)\n",
    "\n",
    "# dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "# rf_clf = RandomForestClassifier(random_state=11)\n",
    "# lr_clf = LogisticRegression(random_state=11)\n",
    "    \n",
    "# dt_clf.fit(train_X,train_y)\n",
    "# rf_clf.fit(train_X,train_y)\n",
    "# lr_clf.fit(train_X,train_y)\n",
    "                        \n",
    "# accuracy_dt = accuracy_score(dt_clf.predict(test_X),test_y)\n",
    "# accuracy_rf = accuracy_score(rf_clf.predict(test_X),test_y)\n",
    "# accuracy_lr = accuracy_score(lr_clf.predict(test_X),test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 충격적인 결과\n",
    "# print(accuracy_dt)\n",
    "# print(accuracy_rf)\n",
    "# print(accuracy_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이상치 제거 : IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['customer_inquiry_history'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier 찾기\n",
    "\n",
    "weight = 1.5\n",
    "Q1 = train_df['customer_inquiry_history'].quantile(0.25)\n",
    "Q3 = train_df['customer_inquiry_history'].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "max_value = Q3 + (IQR * weight)\n",
    "min_value = Q1 - (IQR * weight)\n",
    "\n",
    "outlier = []\n",
    "outlier_index = []\n",
    "for i in train_df['customer_inquiry_history'].index:\n",
    "    value = train_df['customer_inquiry_history'][i]\n",
    "\n",
    "    if value > max_value or value < min_value:\n",
    "        outlier.append(value)       \n",
    "        outlier_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_feature(dataFrame):\n",
    "    columns = dataFrame.columns\n",
    "    outlier = []\n",
    "    outlier_index = []\n",
    "    \n",
    "    for column in columns:\n",
    "        # 칼럼별 이상치 범위 계산\n",
    "        weight = 1.5\n",
    "        Q1 = dataFrame[column].quantile(0.25)\n",
    "        Q3 = dataFrame[column].quantile(0.75)\n",
    "        IQR = Q3-Q1\n",
    "        max_value = Q3 + (IQR * weight)\n",
    "        min_value = Q1 - (IQR * weight)\n",
    "\n",
    "        # 칼럼별 이상치 여부 확인 후 인덱스 담기\n",
    "        for i in train_df[column].index:\n",
    "            value = train_df[column][i]\n",
    "\n",
    "            if value > max_value or value < min_value:\n",
    "                outlier.append(value)       \n",
    "                outlier_index.append(i)\n",
    "                \n",
    "    # 칼럼별 이상치가 있는 행 인덱스 중복 제거\n",
    "    outlier_index = list(set(outlier_index))\n",
    "    \n",
    "    # 이상치 있는 행 제거\n",
    "    dataFrame.drop(outlier_index, axis=0, inplace=True)\n",
    "        \n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제거 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_feature(train_df)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(4,3, figsize = (20,30))\n",
    "\n",
    "for idx,col in enumerate(train_df.columns[1:13]):\n",
    "    \n",
    "    row_index = idx // 3\n",
    "    col_index = idx % 3\n",
    "\n",
    "    sns.boxplot(x = train_df['target'],y = train_df[col], color = 'darkseagreen', ax = ax[row_index,col_index])\n",
    "    ax[row_index,col_index].set_title('boxplot for %s' % col)\n",
    "plt.show()\n",
    "\n",
    "plt.tight_layout(pad=5)\n",
    "plt.subplots_adjust(wspace=0, hspace=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 내용 정리\n",
    " 1. user_id 칼럼 삭제\n",
    " 2. object 타입 칼럼 라벨인코딩\n",
    " 3. 이상치 제거 -> IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def drop_feature(dataFrame):\n",
    "    dataFrame.drop('user_id',axis=1,inplace=True)\n",
    "    return dataFrame\n",
    "    \n",
    "def encoding_feature(dataFrame):    \n",
    "    object_columns = dataFrame.select_dtypes(include='object')\n",
    "    for column in object_columns.columns:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataFrame[column])\n",
    "        dataFrame[column] = le.transform(dataFrame[column])\n",
    "    return dataFrame\n",
    "\n",
    "def outlier_feature(dataFrame):\n",
    "    columns = dataFrame.columns\n",
    "    outlier = []\n",
    "    outlier_index = []\n",
    "    \n",
    "    for column in columns:\n",
    "        # 칼럼별 이상치 범위 계산\n",
    "        weight = 1.5\n",
    "        Q1 = dataFrame[column].quantile(0.25)\n",
    "        Q3 = dataFrame[column].quantile(0.75)\n",
    "        IQR = Q3-Q1\n",
    "        max_value = Q3 + (IQR * weight)\n",
    "        min_value = Q1 - (IQR * weight)\n",
    "\n",
    "        # 칼럼별 이상치 여부 확인 후 인덱스 담기\n",
    "        for i in train_df[column].index:\n",
    "            value = train_df[column][i]\n",
    "\n",
    "            if value > max_value or value < min_value:\n",
    "                outlier.append(value)       \n",
    "                outlier_index.append(i)\n",
    "                \n",
    "    # 칼럼별 이상치가 있는 행 인덱스 중복 제거\n",
    "    outlier_index = list(set(outlier_index))\n",
    "    \n",
    "    # 이상치 있는 행 제거\n",
    "    dataFrame.drop(outlier_index, axis=0, inplace=True)\n",
    "        \n",
    "    return dataFrame\n",
    "        \n",
    "        \n",
    "def preprocessing_df(dataFrame):\n",
    "    dataFrame = drop_feature(dataFrame)\n",
    "    dataFrame = encoding_feature(dataFrame)\n",
    "    dataFrame = outlier_feature(dataFrame)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9115 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   subscription_duration              9115 non-null   int64  \n",
      " 1   recent_login_time                  9115 non-null   int64  \n",
      " 2   average_login_time                 9115 non-null   float64\n",
      " 3   average_time_per_learning_session  9115 non-null   float64\n",
      " 4   monthly_active_learning_days       9115 non-null   int64  \n",
      " 5   total_completed_courses            9115 non-null   int64  \n",
      " 6   recent_learning_achievement        9115 non-null   float64\n",
      " 7   abandoned_learning_sessions        9115 non-null   int64  \n",
      " 8   community_engagement_level         9115 non-null   int64  \n",
      " 9   preferred_difficulty_level         9115 non-null   int64  \n",
      " 10  subscription_type                  9115 non-null   int64  \n",
      " 11  customer_inquiry_history           9115 non-null   int64  \n",
      " 12  payment_pattern                    9115 non-null   int64  \n",
      " 13  target                             9115 non-null   int64  \n",
      "dtypes: float64(3), int64(11)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_df = preprocessing_df(train_df)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   subscription_duration              10000 non-null  int64  \n",
      " 1   recent_login_time                  10000 non-null  int64  \n",
      " 2   average_login_time                 10000 non-null  float64\n",
      " 3   average_time_per_learning_session  10000 non-null  float64\n",
      " 4   monthly_active_learning_days       10000 non-null  int64  \n",
      " 5   total_completed_courses            10000 non-null  int64  \n",
      " 6   recent_learning_achievement        10000 non-null  float64\n",
      " 7   abandoned_learning_sessions        10000 non-null  int64  \n",
      " 8   community_engagement_level         10000 non-null  int64  \n",
      " 9   preferred_difficulty_level         10000 non-null  int64  \n",
      " 10  subscription_type                  10000 non-null  int64  \n",
      " 11  customer_inquiry_history           10000 non-null  int64  \n",
      " 12  payment_pattern                    10000 non-null  int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 1015.8 KB\n"
     ]
    }
   ],
   "source": [
    "test_df = preprocessing_df(test_df)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 머신러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['target'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brielle/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train = train_df['target']\n",
    "X_train = train_df.drop('target',axis=1)\n",
    "\n",
    "train_X,test_X,train_y,test_y = train_test_split(X_train,y_train,\n",
    "                                               test_size=0.2,random_state=11)\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression(random_state=11)\n",
    "    \n",
    "dt_clf.fit(train_X,train_y)\n",
    "rf_clf.fit(train_X,train_y)\n",
    "lr_clf.fit(train_X,train_y)\n",
    "                        \n",
    "accuracy_dt = accuracy_score(dt_clf.predict(test_X),test_y)\n",
    "accuracy_rf = accuracy_score(rf_clf.predict(test_X),test_y)\n",
    "accuracy_lr = accuracy_score(lr_clf.predict(test_X),test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5117937465715853\n",
      "0.5655512890839276\n",
      "0.578167855183763\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_dt)\n",
    "print(accuracy_rf)\n",
    "print(accuracy_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brielle/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brielle/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brielle/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brielle/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brielle/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "CV_scores_dt = cross_val_score(dt_clf,train_X,train_y,scoring='accuracy',cv=5)\n",
    "CV_scores_rf = cross_val_score(rf_clf,train_X,train_y,scoring='accuracy',cv=5)\n",
    "CV_scores_lr = cross_val_score(lr_clf,train_X,train_y,scoring='accuracy',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5128881705811618\n",
      "0.5807720115718998\n",
      "0.6060066133200954\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(CV_scores_dt))\n",
    "print(np.mean(CV_scores_rf))\n",
    "print(np.mean(CV_scores_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피쳐 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['preferred_difficulty_level','subscription_type','target']\n",
    "uncategorical = train_df.drop(categorical,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df)\n",
    "train_scaled = scaler.transform(train_df)\n",
    "train_df_scaled = pd.DataFrame(data=train_scaled, columns=train_df.columns)\n",
    "\n",
    "train_df_scaled[categorical] = train_df[categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscription_duration</th>\n",
       "      <th>recent_login_time</th>\n",
       "      <th>average_login_time</th>\n",
       "      <th>average_time_per_learning_session</th>\n",
       "      <th>monthly_active_learning_days</th>\n",
       "      <th>total_completed_courses</th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>abandoned_learning_sessions</th>\n",
       "      <th>community_engagement_level</th>\n",
       "      <th>preferred_difficulty_level</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>customer_inquiry_history</th>\n",
       "      <th>payment_pattern</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.115000e+03</td>\n",
       "      <td>9.115000e+03</td>\n",
       "      <td>9.115000e+03</td>\n",
       "      <td>9.115000e+03</td>\n",
       "      <td>9.115000e+03</td>\n",
       "      <td>9.115000e+03</td>\n",
       "      <td>9.115000e+03</td>\n",
       "      <td>9.115000e+03</td>\n",
       "      <td>9.115000e+03</td>\n",
       "      <td>8300.000000</td>\n",
       "      <td>8300.000000</td>\n",
       "      <td>9.115000e+03</td>\n",
       "      <td>9.115000e+03</td>\n",
       "      <td>8300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.924438e-17</td>\n",
       "      <td>4.677188e-17</td>\n",
       "      <td>6.920289e-16</td>\n",
       "      <td>7.951219e-17</td>\n",
       "      <td>4.521281e-17</td>\n",
       "      <td>-2.408752e-16</td>\n",
       "      <td>6.587039e-16</td>\n",
       "      <td>1.492802e-16</td>\n",
       "      <td>1.262841e-16</td>\n",
       "      <td>1.099759</td>\n",
       "      <td>0.383012</td>\n",
       "      <td>8.574844e-18</td>\n",
       "      <td>1.247250e-17</td>\n",
       "      <td>0.598313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000055e+00</td>\n",
       "      <td>1.000055e+00</td>\n",
       "      <td>1.000055e+00</td>\n",
       "      <td>1.000055e+00</td>\n",
       "      <td>1.000055e+00</td>\n",
       "      <td>1.000055e+00</td>\n",
       "      <td>1.000055e+00</td>\n",
       "      <td>1.000055e+00</td>\n",
       "      <td>1.000055e+00</td>\n",
       "      <td>0.707439</td>\n",
       "      <td>0.486150</td>\n",
       "      <td>1.000055e+00</td>\n",
       "      <td>1.000055e+00</td>\n",
       "      <td>0.490269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.646819e+00</td>\n",
       "      <td>-1.676844e+00</td>\n",
       "      <td>-2.735967e+00</td>\n",
       "      <td>-1.178933e+00</td>\n",
       "      <td>-1.672269e+00</td>\n",
       "      <td>-2.593915e+00</td>\n",
       "      <td>-2.737837e+00</td>\n",
       "      <td>-1.808359e+00</td>\n",
       "      <td>-2.249703e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.433210e+00</td>\n",
       "      <td>-1.515470e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.904038e-01</td>\n",
       "      <td>-8.410551e-01</td>\n",
       "      <td>-6.739461e-01</td>\n",
       "      <td>-8.100372e-01</td>\n",
       "      <td>-8.052603e-01</td>\n",
       "      <td>-6.080169e-01</td>\n",
       "      <td>-6.967423e-01</td>\n",
       "      <td>-5.918871e-01</td>\n",
       "      <td>-6.781178e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.108597e-01</td>\n",
       "      <td>-1.083014e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.729423e-02</td>\n",
       "      <td>-5.265845e-03</td>\n",
       "      <td>-5.818882e-03</td>\n",
       "      <td>-2.822042e-01</td>\n",
       "      <td>6.174798e-02</td>\n",
       "      <td>-4.061746e-02</td>\n",
       "      <td>4.971651e-03</td>\n",
       "      <td>1.634863e-02</td>\n",
       "      <td>1.076747e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.149104e-02</td>\n",
       "      <td>2.143539e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.249923e-01</td>\n",
       "      <td>8.305234e-01</td>\n",
       "      <td>6.813112e-01</td>\n",
       "      <td>5.584841e-01</td>\n",
       "      <td>9.287562e-01</td>\n",
       "      <td>8.104817e-01</td>\n",
       "      <td>6.840769e-01</td>\n",
       "      <td>6.245844e-01</td>\n",
       "      <td>8.934672e-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.338418e-01</td>\n",
       "      <td>1.079266e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.681407e+00</td>\n",
       "      <td>1.666313e+00</td>\n",
       "      <td>2.741840e+00</td>\n",
       "      <td>3.075431e+00</td>\n",
       "      <td>1.651263e+00</td>\n",
       "      <td>2.796380e+00</td>\n",
       "      <td>2.749703e+00</td>\n",
       "      <td>2.449292e+00</td>\n",
       "      <td>8.934672e-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.900894e+00</td>\n",
       "      <td>1.511722e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subscription_duration  recent_login_time  average_login_time  \\\n",
       "count           9.115000e+03       9.115000e+03        9.115000e+03   \n",
       "mean            5.924438e-17       4.677188e-17        6.920289e-16   \n",
       "std             1.000055e+00       1.000055e+00        1.000055e+00   \n",
       "min            -1.646819e+00      -1.676844e+00       -2.735967e+00   \n",
       "25%            -8.904038e-01      -8.410551e-01       -6.739461e-01   \n",
       "50%             1.729423e-02      -5.265845e-03       -5.818882e-03   \n",
       "75%             9.249923e-01       8.305234e-01        6.813112e-01   \n",
       "max             1.681407e+00       1.666313e+00        2.741840e+00   \n",
       "\n",
       "       average_time_per_learning_session  monthly_active_learning_days  \\\n",
       "count                       9.115000e+03                  9.115000e+03   \n",
       "mean                        7.951219e-17                  4.521281e-17   \n",
       "std                         1.000055e+00                  1.000055e+00   \n",
       "min                        -1.178933e+00                 -1.672269e+00   \n",
       "25%                        -8.100372e-01                 -8.052603e-01   \n",
       "50%                        -2.822042e-01                  6.174798e-02   \n",
       "75%                         5.584841e-01                  9.287562e-01   \n",
       "max                         3.075431e+00                  1.651263e+00   \n",
       "\n",
       "       total_completed_courses  recent_learning_achievement  \\\n",
       "count             9.115000e+03                 9.115000e+03   \n",
       "mean             -2.408752e-16                 6.587039e-16   \n",
       "std               1.000055e+00                 1.000055e+00   \n",
       "min              -2.593915e+00                -2.737837e+00   \n",
       "25%              -6.080169e-01                -6.967423e-01   \n",
       "50%              -4.061746e-02                 4.971651e-03   \n",
       "75%               8.104817e-01                 6.840769e-01   \n",
       "max               2.796380e+00                 2.749703e+00   \n",
       "\n",
       "       abandoned_learning_sessions  community_engagement_level  \\\n",
       "count                 9.115000e+03                9.115000e+03   \n",
       "mean                  1.492802e-16                1.262841e-16   \n",
       "std                   1.000055e+00                1.000055e+00   \n",
       "min                  -1.808359e+00               -2.249703e+00   \n",
       "25%                  -5.918871e-01               -6.781178e-01   \n",
       "50%                   1.634863e-02                1.076747e-01   \n",
       "75%                   6.245844e-01                8.934672e-01   \n",
       "max                   2.449292e+00                8.934672e-01   \n",
       "\n",
       "       preferred_difficulty_level  subscription_type  \\\n",
       "count                 8300.000000        8300.000000   \n",
       "mean                     1.099759           0.383012   \n",
       "std                      0.707439           0.486150   \n",
       "min                      0.000000           0.000000   \n",
       "25%                      1.000000           0.000000   \n",
       "50%                      1.000000           0.000000   \n",
       "75%                      2.000000           1.000000   \n",
       "max                      2.000000           1.000000   \n",
       "\n",
       "       customer_inquiry_history  payment_pattern       target  \n",
       "count              9.115000e+03     9.115000e+03  8300.000000  \n",
       "mean               8.574844e-18     1.247250e-17     0.598313  \n",
       "std                1.000055e+00     1.000055e+00     0.490269  \n",
       "min               -1.433210e+00    -1.515470e+00     0.000000  \n",
       "25%               -7.108597e-01    -1.083014e+00     0.000000  \n",
       "50%                1.149104e-02     2.143539e-01     1.000000  \n",
       "75%                7.338418e-01     1.079266e+00     1.000000  \n",
       "max                2.900894e+00     1.511722e+00     1.000000  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_scaled.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train = train_df_scaled['target']\n",
    "X_train = train_df_scaled.drop('target',axis=1)\n",
    "\n",
    "train_X,test_X,train_y,test_y = train_test_split(X_train,y_train,\n",
    "                                               test_size=0.2,random_state=11)\n",
    "\n",
    "# print(train_X)\n",
    "# print(test_X)\n",
    "# print(train_y)\n",
    "# print(test_y)\n",
    "\n",
    "\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression(random_state=11)\n",
    "    \n",
    "dt_clf.fit(train_X,train_y)\n",
    "rf_clf.fit(train_X,train_y)\n",
    "lr_clf.fit(train_X,train_y)\n",
    "                        \n",
    "accuracy_dt = accuracy_score(dt_clf.predict(test_X),test_y)\n",
    "accuracy_rf = accuracy_score(rf_clf.predict(test_X),test_y)\n",
    "accuracy_lr = accuracy_score(lr_clf.predict(test_X),test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5095995611629183\n",
      "0.5792649478880966\n",
      "0.5929786066922655\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_dt)\n",
    "print(accuracy_rf)\n",
    "print(accuracy_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 의사결정나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth':[2,5,10],'min_samples_leaf':[2,5,10]}\n",
    "grid_dt_clf = GridSearchCV(dt_clf,param_grid = parameters,cv=5, refit=True)\n",
    "grid_dt_clf.fit(X_train,y_train)\n",
    "\n",
    "scores_df_dt = pd.DataFrame(grid_dt_clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.600549</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.600549</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.600549</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.598354</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.598025</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.597257</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.580143</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.580911</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.580911</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      params  mean_test_score  rank_test_score\n",
       "0    {'max_depth': 2, 'min_samples_leaf': 2}         0.600549                1\n",
       "1    {'max_depth': 2, 'min_samples_leaf': 5}         0.600549                1\n",
       "2   {'max_depth': 2, 'min_samples_leaf': 10}         0.600549                1\n",
       "3    {'max_depth': 5, 'min_samples_leaf': 2}         0.598354                4\n",
       "4    {'max_depth': 5, 'min_samples_leaf': 5}         0.598025                5\n",
       "5   {'max_depth': 5, 'min_samples_leaf': 10}         0.597257                6\n",
       "6   {'max_depth': 10, 'min_samples_leaf': 2}         0.580143                9\n",
       "7   {'max_depth': 10, 'min_samples_leaf': 5}         0.580911                7\n",
       "8  {'max_depth': 10, 'min_samples_leaf': 10}         0.580911                8"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df_dt[['params','mean_test_score','rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이퍼 파라미터:  {'max_depth': 2, 'min_samples_leaf': 2}\n",
      "GridSearchCV 최고 정확도: 0.6005\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 하이퍼 파라미터: ',grid_dt_clf.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dt_clf.best_score_))\n",
    "best_dt_clf = grid_dt_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트에서의 DecisionTreeClassifier 정확도: 0.5782\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행\n",
    "\n",
    "best_dt_pred = best_dt_clf.predict(test_X)\n",
    "\n",
    "accuracy = accuracy_score(test_y,best_dt_pred)\n",
    "\n",
    "print('테스트 세트에서의 DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6059\n"
     ]
    }
   ],
   "source": [
    "# 교차검증\n",
    "best_dt_clf_score = cross_val_score(best_dt_clf,train_X,train_y,scoring='accuracy',cv=5)\n",
    "print(np.round(np.mean(best_dt_clf_score),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 로지스틱회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'penalty': ['l2'], 'C': [0.01, 0.1, 1, 5, 10]}\n",
    "grid_lr_clf = GridSearchCV(lr_clf, param_grid=params, cv=5, refit=True)\n",
    "grid_lr_clf.fit(X_train,y_train)\n",
    "\n",
    "scores_df_lr = pd.DataFrame(grid_lr_clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.591991</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.591772</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 5, 'penalty': 'l2'}</td>\n",
       "      <td>0.591662</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.591662</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         params  mean_test_score  rank_test_score\n",
       "0  {'C': 0.01, 'penalty': 'l2'}         0.595283                1\n",
       "1   {'C': 0.1, 'penalty': 'l2'}         0.591991                2\n",
       "2     {'C': 1, 'penalty': 'l2'}         0.591772                3\n",
       "3     {'C': 5, 'penalty': 'l2'}         0.591662                4\n",
       "4    {'C': 10, 'penalty': 'l2'}         0.591662                4"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df_lr[['params','mean_test_score','rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do\n",
    "* 추가 전처리\n",
    "1. feature들 중에 연관있는 애들끼리 묶어보기 (학습시간 / 커뮤니티 참여 등)\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
